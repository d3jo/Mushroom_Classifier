{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\joaju\\\\OneDrive\\\\Projects\\\\Mushroom_Classifier\\\\mushroom_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df.drop(['class'], axis = 1))\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs of the train_test_split function, so that training from X and y the result is stored in the four variables.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>676</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.079154</td>\n",
       "      <td>1064</td>\n",
       "      <td>6</td>\n",
       "      <td>1.804273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>872</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.571275</td>\n",
       "      <td>1648</td>\n",
       "      <td>11</td>\n",
       "      <td>0.888450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41596</th>\n",
       "      <td>508</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.504906</td>\n",
       "      <td>395</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50425</th>\n",
       "      <td>443</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2.013794</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.888450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26260</th>\n",
       "      <td>1425</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.218419</td>\n",
       "      <td>3011</td>\n",
       "      <td>11</td>\n",
       "      <td>0.888450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
       "5047            676          2                1          11     0.079154   \n",
       "1002            872          2                0          10     1.571275   \n",
       "41596           508          2                6           5     0.504906   \n",
       "50425           443          3                0          10     2.013794   \n",
       "26260          1425          6                1           5     0.218419   \n",
       "\n",
       "       stem-width  stem-color    season  \n",
       "5047         1064           6  1.804273  \n",
       "1002         1648          11  0.888450  \n",
       "41596         395          11  0.943195  \n",
       "50425           0           2  0.888450  \n",
       "26260        3011          11  0.888450  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5047     1\n",
       "1002     0\n",
       "41596    0\n",
       "50425    1\n",
       "26260    1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our Model by adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaju\\anaconda4\\envs\\newenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add layers to the neural networks\n",
    "# units : how many neurons in the dense layer\n",
    "# activation function\n",
    "model.add(Dense(units=32, activation='relu', input_dim=len(X_train.columns)))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have detected that our model does not increase in accuracy from 200 to 500 epochs.\n",
    "So we will apply early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5499 - loss: 0.6711 - val_accuracy: 0.5441 - val_loss: 0.6750\n",
      "Epoch 2/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5433 - loss: 0.6764 - val_accuracy: 0.5459 - val_loss: 0.6753\n",
      "Epoch 3/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5512 - loss: 0.6748 - val_accuracy: 0.5459 - val_loss: 0.6741\n",
      "Epoch 4/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5495 - loss: 0.6747 - val_accuracy: 0.5459 - val_loss: 0.6720\n",
      "Epoch 5/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5519 - loss: 0.6722 - val_accuracy: 0.5459 - val_loss: 0.6712\n",
      "Epoch 6/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5495 - loss: 0.6712 - val_accuracy: 0.5459 - val_loss: 0.6707\n",
      "Epoch 7/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5501 - loss: 0.6714 - val_accuracy: 0.5459 - val_loss: 0.6709\n",
      "Epoch 8/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5478 - loss: 0.6718 - val_accuracy: 0.5459 - val_loss: 0.6710\n",
      "Epoch 9/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5510 - loss: 0.6704 - val_accuracy: 0.5459 - val_loss: 0.6708\n",
      "Epoch 10/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5530 - loss: 0.6712 - val_accuracy: 0.5459 - val_loss: 0.6702\n",
      "Epoch 11/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5505 - loss: 0.6702 - val_accuracy: 0.5459 - val_loss: 0.6704\n",
      "Epoch 12/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5516 - loss: 0.6699 - val_accuracy: 0.5459 - val_loss: 0.6698\n",
      "Epoch 13/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5465 - loss: 0.6714 - val_accuracy: 0.5459 - val_loss: 0.6700\n",
      "Epoch 14/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5521 - loss: 0.6686 - val_accuracy: 0.5459 - val_loss: 0.6697\n",
      "Epoch 15/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5473 - loss: 0.6697 - val_accuracy: 0.5459 - val_loss: 0.6695\n",
      "Epoch 16/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5553 - loss: 0.6692 - val_accuracy: 0.5459 - val_loss: 0.6693\n",
      "Epoch 17/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5537 - loss: 0.6694 - val_accuracy: 0.5459 - val_loss: 0.6691\n",
      "Epoch 18/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5505 - loss: 0.6693 - val_accuracy: 0.5459 - val_loss: 0.6693\n",
      "Epoch 19/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5484 - loss: 0.6695 - val_accuracy: 0.5459 - val_loss: 0.6689\n",
      "Epoch 20/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5512 - loss: 0.6697 - val_accuracy: 0.5459 - val_loss: 0.6689\n",
      "Epoch 21/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5468 - loss: 0.6703 - val_accuracy: 0.5459 - val_loss: 0.6688\n",
      "Epoch 22/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5518 - loss: 0.6684 - val_accuracy: 0.5459 - val_loss: 0.6687\n",
      "Epoch 23/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5524 - loss: 0.6679 - val_accuracy: 0.5459 - val_loss: 0.6688\n",
      "Epoch 24/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5556 - loss: 0.6686 - val_accuracy: 0.5459 - val_loss: 0.6695\n",
      "Epoch 25/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5538 - loss: 0.6683 - val_accuracy: 0.5459 - val_loss: 0.6684\n",
      "Epoch 26/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5520 - loss: 0.6708 - val_accuracy: 0.5459 - val_loss: 0.6724\n",
      "Epoch 27/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5485 - loss: 0.6734 - val_accuracy: 0.5459 - val_loss: 0.6739\n",
      "Epoch 28/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5506 - loss: 0.6738 - val_accuracy: 0.5459 - val_loss: 0.6726\n",
      "Epoch 29/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5518 - loss: 0.6732 - val_accuracy: 0.5459 - val_loss: 0.6722\n",
      "Epoch 30/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5479 - loss: 0.6749 - val_accuracy: 0.5459 - val_loss: 0.6739\n",
      "Epoch 31/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5478 - loss: 0.6740 - val_accuracy: 0.5459 - val_loss: 0.6727\n",
      "Epoch 32/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5513 - loss: 0.6726 - val_accuracy: 0.5459 - val_loss: 0.6722\n",
      "Epoch 33/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5540 - loss: 0.6724 - val_accuracy: 0.5459 - val_loss: 0.6742\n",
      "Epoch 34/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5549 - loss: 0.6727 - val_accuracy: 0.5459 - val_loss: 0.6722\n",
      "Epoch 35/200\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5505 - loss: 0.6732 - val_accuracy: 0.5459 - val_loss: 0.6724\n"
     ]
    }
   ],
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Retrain the model applying the early stopping\n",
    "history = model.fit(X_train, y_train, epochs=200, \n",
    "                    batch_size=64, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-evaluate the Early Stopping Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5539 - loss: 0.6689\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and Load our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our model in a file or directory so that it saves\n",
    "# the training configuration such as optimizer, loss and metrics.\n",
    "# it can be loaded and used later without having to retrain it.\n",
    "\n",
    "model.save('tfmodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the model from the memory in this environment.\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later on load_model function will load our saved model as follows.\n",
    "\n",
    "model = load_model('tfmodel.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
